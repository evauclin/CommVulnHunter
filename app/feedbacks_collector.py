# feedback_collector.py
"""
SystÃ¨me de collecte de feedback et rÃ©entraÃ®nement automatique du modÃ¨le ML
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime
import os
import pickle
import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import sqlite3
import threading
import time
from pathlib import Path


class FeedbackCollector:
    """Collecte et traite les feedbacks utilisateurs"""

    def __init__(self, db_path="feedback.db", model_dir="model/"):
        self.db_path = db_path
        self.model_dir = Path(model_dir)
        self.init_database()

    def init_database(self):
        """Initialise la base de donnÃ©es des feedbacks"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS feedbacks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                email_text TEXT NOT NULL,
                predicted_label TEXT NOT NULL,
                user_satisfaction TEXT NOT NULL,
                correct_label TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                confidence_score REAL,
                processed BOOLEAN DEFAULT FALSE
            )
        ''')

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS retraining_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                num_feedbacks INTEGER,
                old_accuracy REAL,
                new_accuracy REAL,
                model_version TEXT,
                status TEXT
            )
        ''')

        conn.commit()
        conn.close()
        print("âœ… Base de donnÃ©es feedback initialisÃ©e")

    def save_feedback(self, email_text, predicted_label, user_satisfaction,
                      confidence_score=None, correct_label=None):
        """Sauvegarde un feedback utilisateur"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Si l'utilisateur n'est pas satisfait, on dÃ©duit le bon label
        if user_satisfaction == "no" and not correct_label:
            correct_label = "benign" if predicted_label == "phishing" else "phishing"
        elif user_satisfaction == "yes":
            correct_label = predicted_label

        cursor.execute('''
            INSERT INTO feedbacks 
            (email_text, predicted_label, user_satisfaction, correct_label, confidence_score)
            VALUES (?, ?, ?, ?, ?)
        ''', (email_text, predicted_label, user_satisfaction, correct_label, confidence_score))

        conn.commit()
        conn.close()

        print(f"ðŸ“ Feedback sauvegardÃ©: {user_satisfaction} pour prÃ©diction {predicted_label}")

        # VÃ©rifier si on doit dÃ©clencher un rÃ©entraÃ®nement
        self.check_retraining_trigger()

    def get_feedback_stats(self):
        """Obtient les statistiques des feedbacks"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Statistiques gÃ©nÃ©rales
        cursor.execute("SELECT COUNT(*) FROM feedbacks")
        total_feedbacks = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM feedbacks WHERE user_satisfaction = 'no'")
        negative_feedbacks = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM feedbacks WHERE processed = FALSE")
        unprocessed_feedbacks = cursor.fetchone()[0]

        # Feedbacks par type de prÃ©diction
        cursor.execute('''
            SELECT predicted_label, user_satisfaction, COUNT(*) 
            FROM feedbacks 
            GROUP BY predicted_label, user_satisfaction
        ''')
        feedback_breakdown = cursor.fetchall()

        conn.close()

        return {
            'total_feedbacks': total_feedbacks,
            'negative_feedbacks': negative_feedbacks,
            'unprocessed_feedbacks': unprocessed_feedbacks,
            'accuracy_rate': (total_feedbacks - negative_feedbacks) / max(total_feedbacks, 1),
            'feedback_breakdown': feedback_breakdown
        }

    def check_retraining_trigger(self):
        """VÃ©rifie si un rÃ©entraÃ®nement doit Ãªtre dÃ©clenchÃ©"""
        stats = self.get_feedback_stats()

        # Conditions de dÃ©clenchement du rÃ©entraÃ®nement
        should_retrain = (
                stats['unprocessed_feedbacks'] >= 50 or  # Au moins 50 nouveaux feedbacks
                (stats['total_feedbacks'] >= 20 and stats['accuracy_rate'] < 0.8)  # PrÃ©cision < 80%
        )

        if should_retrain:
            print("ðŸš¨ DÃ©clenchement du rÃ©entraÃ®nement automatique")
            self.trigger_retraining()

    def trigger_retraining(self):
        """DÃ©clenche le rÃ©entraÃ®nement en arriÃ¨re-plan"""

        def retrain():
            retrainer = ModelRetrainer(self.db_path, self.model_dir)
            retrainer.retrain_model()

        # Lancer en thread sÃ©parÃ© pour ne pas bloquer l'API
        thread = threading.Thread(target=retrain)
        thread.daemon = True
        thread.start()

    def export_training_data(self):
        """Exporte les feedbacks comme donnÃ©es d'entraÃ®nement"""
        conn = sqlite3.connect(self.db_path)

        df = pd.read_sql_query('''
            SELECT email_text as text, correct_label as label, confidence_score
            FROM feedbacks 
            WHERE correct_label IS NOT NULL AND processed = FALSE
        ''', conn)

        conn.close()

        return df


class ModelRetrainer:
    """GÃ¨re le rÃ©entraÃ®nement du modÃ¨le avec les feedbacks"""

    def __init__(self, db_path="feedback.db", model_dir="model/"):
        self.db_path = db_path
        self.model_dir = Path(model_dir)
        self.load_model_artifacts()

    def load_model_artifacts(self):
        """Charge le modÃ¨le et ses artefacts"""
        try:
            self.model = load_model(self.model_dir / 'best_lstm_model.keras')

            with open(self.model_dir / 'tokenizer.pkl', 'rb') as f:
                self.tokenizer = pickle.load(f)

            with open(self.model_dir / 'scaler.pkl', 'rb') as f:
                self.scaler = pickle.load(f)

            with open(self.model_dir / 'label_encoder.pkl', 'rb') as f:
                self.label_encoder = pickle.load(f)

            print("âœ… ModÃ¨le et artefacts chargÃ©s")
        except Exception as e:
            print(f"âŒ Erreur chargement modÃ¨le: {e}")
            raise

    def preprocess_feedback_data(self, df):
        """PrÃ©processe les donnÃ©es de feedback pour l'entraÃ®nement"""
        from train_model import LSTMPhishingDetector

        # Utiliser le mÃªme preprocessing que l'entraÃ®nement initial
        detector = LSTMPhishingDetector()
        detector.tokenizer = self.tokenizer
        detector.scaler = self.scaler
        detector.label_encoder = self.label_encoder

        # PrÃ©parer les sÃ©quences
        X_text, X_num = detector.prepare_sequences(df, is_training=False)
        y = self.label_encoder.transform(df['label'])

        return X_text, X_num, y

    def incremental_training(self, X_text_new, X_num_new, y_new, epochs=5):
        """Effectue un entraÃ®nement incrÃ©mental"""
        print(f"ðŸ”„ EntraÃ®nement incrÃ©mental sur {len(y_new)} Ã©chantillons...")

        # Compilation avec un learning rate plus faible pour l'ajustement fin
        from tensorflow.keras.optimizers import Adam
        self.model.compile(
            optimizer=Adam(learning_rate=0.0001),  # Learning rate rÃ©duit
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )

        # EntraÃ®nement incrÃ©mental
        history = self.model.fit(
            [X_text_new, X_num_new], y_new,
            batch_size=16,
            epochs=epochs,
            verbose=1,
            validation_split=0.2
        )

        return history

    def evaluate_improvement(self, X_text_test, X_num_test, y_test):
        """Ã‰value l'amÃ©lioration du modÃ¨le"""
        y_pred_proba = self.model.predict([X_text_test, X_num_test])
        y_pred = (y_pred_proba > 0.5).astype(int)

        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True)

        return accuracy, report

    def retrain_model(self):
        """Processus complet de rÃ©entraÃ®nement"""
        print("ðŸš€ DÃ‰BUT DU RÃ‰ENTRAÃŽNEMENT AUTOMATIQUE")
        print("=" * 50)

        try:
            # 1. Collecter les feedbacks non traitÃ©s
            collector = FeedbackCollector(self.db_path)
            feedback_df = collector.export_training_data()

            if len(feedback_df) < 10:
                print("âš ï¸ Pas assez de feedbacks pour rÃ©entraÃ®ner (minimum 10)")
                return

            print(f"ðŸ“Š {len(feedback_df)} nouveaux feedbacks collectÃ©s")

            # 2. PrÃ©processer les donnÃ©es
            X_text_new, X_num_new, y_new = self.preprocess_feedback_data(feedback_df)

            # 3. Ã‰valuation avant rÃ©entraÃ®nement
            old_accuracy, _ = self.evaluate_improvement(X_text_new, X_num_new, y_new)
            print(f"ðŸ“ˆ PrÃ©cision avant rÃ©entraÃ®nement: {old_accuracy:.4f}")

            # 4. Sauvegarder le modÃ¨le actuel comme backup
            backup_path = self.model_dir / f"backup_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.keras"
            self.model.save(backup_path)
            print(f"ðŸ’¾ Sauvegarde crÃ©Ã©e: {backup_path}")

            # 5. EntraÃ®nement incrÃ©mental
            history = self.incremental_training(X_text_new, X_num_new, y_new)

            # 6. Ã‰valuation aprÃ¨s rÃ©entraÃ®nement
            new_accuracy, report = self.evaluate_improvement(X_text_new, X_num_new, y_new)
            print(f"ðŸ“ˆ PrÃ©cision aprÃ¨s rÃ©entraÃ®nement: {new_accuracy:.4f}")

            # 7. DÃ©cider si on garde le nouveau modÃ¨le
            if new_accuracy > old_accuracy * 0.95:  # Au moins 95% de la performance prÃ©cÃ©dente
                # Sauvegarder le nouveau modÃ¨le
                new_model_path = self.model_dir / 'best_lstm_model.keras'
                self.model.save(new_model_path)

                # Marquer les feedbacks comme traitÃ©s
                self.mark_feedbacks_processed()

                # Logger le rÃ©entraÃ®nement
                self.log_retraining(len(feedback_df), old_accuracy, new_accuracy, "SUCCESS")

                print("âœ… Nouveau modÃ¨le sauvegardÃ© avec succÃ¨s")

            else:
                # Restaurer le modÃ¨le prÃ©cÃ©dent
                self.model = load_model(backup_path)
                self.log_retraining(len(feedback_df), old_accuracy, new_accuracy, "REVERTED")

                print("âŒ Performance dÃ©gradÃ©e - modÃ¨le prÃ©cÃ©dent restaurÃ©")

        except Exception as e:
            print(f"âŒ Erreur durant le rÃ©entraÃ®nement: {e}")
            self.log_retraining(0, 0, 0, f"ERROR: {e}")

    def mark_feedbacks_processed(self):
        """Marque les feedbacks comme traitÃ©s"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("UPDATE feedbacks SET processed = TRUE WHERE processed = FALSE")
        conn.commit()
        conn.close()

        print("âœ… Feedbacks marquÃ©s comme traitÃ©s")

    def log_retraining(self, num_feedbacks, old_accuracy, new_accuracy, status):
        """Enregistre les logs de rÃ©entraÃ®nement"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO retraining_logs 
            (num_feedbacks, old_accuracy, new_accuracy, model_version, status)
            VALUES (?, ?, ?, ?, ?)
        ''', (num_feedbacks, old_accuracy, new_accuracy,
              datetime.now().strftime('%Y%m%d_%H%M%S'), status))

        conn.commit()
        conn.close()


# IntÃ©gration avec l'API FastAPI
class FeedbackAPI:
    """Extension de l'API pour gÃ©rer les feedbacks"""

    def __init__(self):
        self.collector = FeedbackCollector()

    def submit_feedback(self, email_text: str, predicted_label: str,
                        user_satisfaction: str, confidence_score: float = None):
        """Endpoint pour soumettre un feedback"""
        try:
            self.collector.save_feedback(
                email_text=email_text,
                predicted_label=predicted_label,
                user_satisfaction=user_satisfaction,
                confidence_score=confidence_score
            )

            return {
                "status": "success",
                "message": "Feedback enregistrÃ©",
                "feedback_stats": self.collector.get_feedback_stats()
            }

        except Exception as e:
            return {
                "status": "error",
                "message": f"Erreur lors de l'enregistrement: {e}"
            }

    def get_feedback_dashboard(self):
        """Endpoint pour les statistiques de feedback"""
        stats = self.collector.get_feedback_stats()

        # Historique des rÃ©entraÃ®nements
        conn = sqlite3.connect(self.collector.db_path)
        retraining_history = pd.read_sql_query(
            "SELECT * FROM retraining_logs ORDER BY timestamp DESC LIMIT 10",
            conn
        ).to_dict('records')
        conn.close()

        return {
            "feedback_stats": stats,
            "retraining_history": retraining_history,
            "last_update": datetime.now().isoformat()
        }


# Script de dÃ©marrage du monitoring automatique
def start_feedback_monitoring():
    """Lance le monitoring automatique des feedbacks"""
    collector = FeedbackCollector()

    def monitor_loop():
        while True:
            time.sleep(3600)  # VÃ©rifier toutes les heures
            collector.check_retraining_trigger()

    # Lancer en arriÃ¨re-plan
    monitor_thread = threading.Thread(target=monitor_loop)
    monitor_thread.daemon = True
    monitor_thread.start()

    print("ðŸ”„ Monitoring des feedbacks dÃ©marrÃ© (vÃ©rification horaire)")


if __name__ == "__main__":
    # Test du systÃ¨me de feedback
    print("ðŸ§ª Test du systÃ¨me de feedback")

    # Initialiser
    collector = FeedbackCollector()

    # Exemples de feedbacks
    test_feedbacks = [
        ("Urgent: Click here to verify your account", "phishing", "yes", 0.85),
        ("Meeting scheduled for tomorrow at 2 PM", "phishing", "no", 0.75),
        ("Win $1000 now! Click here!", "phishing", "yes", 0.92),
        ("Thanks for the report, great work!", "benign", "yes", 0.65),
    ]

    for email_text, predicted, satisfaction, confidence in test_feedbacks:
        collector.save_feedback(email_text, predicted, satisfaction, confidence)

    # Afficher les stats
    stats = collector.get_feedback_stats()
    print(f"ðŸ“Š Statistiques: {stats}")

    # Test du rÃ©entraÃ®nement (avec donnÃ©es factices)
    if stats['unprocessed_feedbacks'] >= 4:
        print("\nðŸš€ Test du rÃ©entraÃ®nement...")
        retrainer = ModelRetrainer()
        # retrainer.retrain_model()  # DÃ©commenter pour tester rÃ©ellement